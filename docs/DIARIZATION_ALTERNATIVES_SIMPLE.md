# –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã Diarization (–ø—Ä–æ—Å—Ç–æ–µ —Ä–µ—à–µ–Ω–∏–µ)

## üéØ –ü—Ä–æ–±–ª–µ–º–∞

–ú–æ–¥–µ–ª—å `pyannote/segmentation-3.0` –Ω–µ —Å–∫–∞—á–∏–≤–∞–µ—Ç—Å—è –∏–∑-–∑–∞ –ø—Ä–æ–±–ª–µ–º —Å –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–µ–π –∏–ª–∏ —Å–µ—Ç—å—é.

## ‚úÖ –†–µ—à–µ–Ω–∏–µ 1: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å—Ç–∞—Ä—É—é –≤–µ—Ä—Å–∏—é pyannote (–†–ï–ö–û–ú–ï–ù–î–£–ï–¢–°–Ø)

### pyannote/speaker-diarization-2.1

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
- ‚úÖ –ù–µ —Ç—Ä–µ–±—É–µ—Ç `segmentation-3.0`
- ‚úÖ –ú–æ–∂–µ—Ç –Ω–µ —Ç—Ä–µ–±–æ–≤–∞—Ç—å –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—é
- ‚úÖ –•–æ—Ä–æ—à–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å
- ‚úÖ –†–∞–±–æ—Ç–∞–µ—Ç —Å WhisperX

**–£—Å—Ç–∞–Ω–æ–≤–∫–∞:**
```powershell
cd C:\prj\converter\backend
.\venv\Scripts\Activate.ps1

# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, –∫–∞–∫–∞—è –≤–µ—Ä—Å–∏—è pyannote —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞
pip show pyannote.audio

# –ï—Å–ª–∏ –Ω—É–∂–Ω–æ, —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å/–æ–±–Ω–æ–≤–∏—Ç—å
pip install pyannote.audio==3.1.1
```

**–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:**

1. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏:
```powershell
python test_diarization_alternatives.py
```

2. –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –¥–æ—Å—Ç—É–ø–Ω–∞, –æ–±–Ω–æ–≤–∏—Ç–µ –∫–æ–¥:

–í `backend/app/services/speech_recognition_optimized.py`, –∏–∑–º–µ–Ω–∏—Ç–µ —Å—Ç—Ä–æ–∫—É 246:

```python
# –ë—ã–ª–æ:
diarize_model = whisperx.DiarizationPipeline(
    use_auth_token=hf_token,
    device=device
)

# –°—Ç–∞–ª–æ (–¥–ª—è –≤–µ—Ä—Å–∏–∏ 2.1):
diarize_model = whisperx.DiarizationPipeline(
    use_auth_token=hf_token,
    device=device,
    model_name="pyannote/speaker-diarization-2.1"  # –î–æ–±–∞–≤—å—Ç–µ —ç—Ç—É —Å—Ç—Ä–æ–∫—É
)
```

**–ï—Å–ª–∏ WhisperX –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —É–∫–∞–∑–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏:**

–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ pyannote –Ω–∞–ø—Ä—è–º—É—é:

```python
from pyannote.audio import Pipeline

# –í –º–µ—Ç–æ–¥–µ _transcribe_with_diarization:
diarize_model = Pipeline.from_pretrained(
    "pyannote/speaker-diarization-2.1",
    use_auth_token=hf_token
)
diarize_model.to(device)

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
diarization = diarize_model({"audio": audio_path})
```

---

## ‚úÖ –†–µ—à–µ–Ω–∏–µ 2: –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–∞—É–∑ (–†–ê–ë–û–¢–ê–ï–¢ –°–†–ê–ó–£)

**–ò–¥–µ—è:** –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–æ–≤–æ–≥–æ —Å–ø–∏–∫–µ—Ä–∞ –ø–æ –¥–ª–∏–Ω–Ω—ã–º –ø–∞—É–∑–∞–º –º–µ–∂–¥—É —Å–µ–≥–º–µ–Ω—Ç–∞–º–∏.

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
- ‚úÖ –†–∞–±–æ—Ç–∞–µ—Ç —Å—Ä–∞–∑—É, –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
- ‚úÖ –ù–µ —Ç—Ä–µ–±—É–µ—Ç –∏–Ω—Ç–µ—Ä–Ω–µ—Ç
- ‚úÖ –ë—ã—Å—Ç—Ä–æ
- ‚úÖ –ü–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –ø—Ä–æ—Å—Ç—ã—Ö —Å–ª—É—á–∞–µ–≤ (–∏–Ω—Ç–µ—Ä–≤—å—é, –¥–∏–∞–ª–æ–≥–∏)

**–ù–µ–¥–æ—Å—Ç–∞—Ç–∫–∏:**
- ‚ö†Ô∏è –ú–µ–Ω–µ–µ —Ç–æ—á–Ω–æ–µ, —á–µ–º pyannote
- ‚ö†Ô∏è –ù–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –ø—Ä–∏ –ø–µ—Ä–µ–∫—Ä—ã–≤–∞—é—â–µ–π—Å—è —Ä–µ—á–∏
- ‚ö†Ô∏è –ú–æ–∂–µ—Ç –æ—à–∏–±–∞—Ç—å—Å—è –ø—Ä–∏ –±—ã—Å—Ç—Ä–æ–π —Å–º–µ–Ω–µ —Å–ø–∏–∫–µ—Ä–æ–≤

**–†–µ–∞–ª–∏–∑–∞—Ü–∏—è:**

–°–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª `backend/app/services/simple_diarization.py`:

```python
"""
–ü—Ä–æ—Å—Ç–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è diarization –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–∞—É–∑ –º–µ–∂–¥—É —Å–µ–≥–º–µ–Ω—Ç–∞–º–∏
"""
from typing import Dict, List

def simple_diarization(segments: List[Dict], pause_threshold: float = 1.0) -> List[Dict]:
    """
    –ü—Ä–æ—Å—Ç–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Ä–æ–ª—è–º –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–∞—É–∑
    
    Args:
        segments: —Å–ø–∏—Å–æ–∫ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –∏–∑ Whisper
        pause_threshold: –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –ø–∞—É–∑–∞ (—Å–µ–∫) –¥–ª—è –Ω–æ–≤–æ–≥–æ —Å–ø–∏–∫–µ—Ä–∞
    
    Returns:
        —Å–ø–∏—Å–æ–∫ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ —Å –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–º –ø–æ–ª–µ–º 'speaker'
    """
    if not segments:
        return []
    
    result = []
    current_speaker = "SPEAKER_00"
    speaker_id = 0
    
    for i, segment in enumerate(segments):
        # –ï—Å–ª–∏ —ç—Ç–æ –ø–µ—Ä–≤—ã–π —Å–µ–≥–º–µ–Ω—Ç - –≤—Å–µ–≥–¥–∞ SPEAKER_00
        if i == 0:
            segment["speaker"] = current_speaker
            result.append(segment)
            continue
        
        # –í—ã—á–∏—Å–ª—è–µ–º –ø–∞—É–∑—É –º–µ–∂–¥—É —Å–µ–≥–º–µ–Ω—Ç–∞–º–∏
        prev_end = segments[i-1].get("end", 0)
        curr_start = segment.get("start", 0)
        pause = curr_start - prev_end
        
        # –ï—Å–ª–∏ –ø–∞—É–∑–∞ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª–∏–Ω–Ω–∞—è - –Ω–æ–≤—ã–π —Å–ø–∏–∫–µ—Ä
        if pause >= pause_threshold:
            speaker_id += 1
            current_speaker = f"SPEAKER_{speaker_id:02d}"
        
        segment["speaker"] = current_speaker
        result.append(segment)
    
    return result
```

**–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤ `speech_recognition_optimized.py`:**

–î–æ–±–∞–≤—å—Ç–µ –∏–º–ø–æ—Ä—Ç:
```python
from .simple_diarization import simple_diarization
```

–ò–∑–º–µ–Ω–∏—Ç–µ –º–µ—Ç–æ–¥ `transcribe`:

```python
# –í–º–µ—Å—Ç–æ enable_diarization –∏ WHISPERX_AVAILABLE:
if enable_diarization:
    # –ü—Ä–æ—Å—Ç–∞—è diarization –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–∞—É–∑
    result = self._transcribe_standard(audio_path, language, model, beam_size, best_of)
    result["segments"] = simple_diarization(result["segments"], pause_threshold=1.0)
    
    # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ —Å–ø–∏–∫–µ—Ä–∞–º
    speakers_text = {}
    for seg in result["segments"]:
        speaker = seg.get("speaker", "SPEAKER_00")
        if speaker not in speakers_text:
            speakers_text[speaker] = []
        speakers_text[speaker].append(seg["text"])
    
    result["speakers"] = {
        speaker: " ".join(texts)
        for speaker, texts in speakers_text.items()
    }
    result["num_speakers"] = len(speakers_text)
    
    return result
```

---

## ‚úÖ –†–µ—à–µ–Ω–∏–µ 3: SpeechBrain (–∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–∞—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∞)

**–£—Å—Ç–∞–Ω–æ–≤–∫–∞:**
```powershell
pip install speechbrain
```

**–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:**
```python
from speechbrain.inference.speaker import SpeakerRecognition

# –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
model = SpeakerRecognition.from_hparams(
    source="speechbrain/spkrec-ecapa-voxceleb",
    savedir="pretrained_models/spkrec-ecapa-voxceleb"
)

# –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ embedding'–æ–≤ –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏
# (—Ç—Ä–µ–±—É–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–ª—è diarization)
```

**–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ:** SpeechBrain –±–æ–ª—å—à–µ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è speaker verification, —á–µ–º –¥–ª—è diarization. –ü–æ—Ç—Ä–µ–±—É–µ—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è.

---

## üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–µ—à–µ–Ω–∏–π

| –†–µ—à–µ–Ω–∏–µ | –¢–æ—á–Ω–æ—Å—Ç—å | –°–∫–æ—Ä–æ—Å—Ç—å | –ü—Ä–æ—Å—Ç–æ—Ç–∞ | –¢—Ä–µ–±—É–µ—Ç –º–æ–¥–µ–ª–∏ |
|---------|----------|----------|----------|----------------|
| **pyannote-2.1** | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚úÖ –î–∞ (~1.2 GB) |
| **–ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞** | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚ùå –ù–µ—Ç |
| **SpeechBrain** | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê | ‚úÖ –î–∞ (~500 MB) |

---

## üöÄ –ë—ã—Å—Ç—Ä–æ–µ –≤–Ω–µ–¥—Ä–µ–Ω–∏–µ (–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)

### –í–∞—Ä–∏–∞–Ω—Ç A: –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ (—Ä–∞–±–æ—Ç–∞–µ—Ç —Å—Ä–∞–∑—É)

1. –°–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª `backend/app/services/simple_diarization.py` —Å –∫–æ–¥–æ–º –≤—ã—à–µ
2. –û–±–Ω–æ–≤–∏—Ç–µ `speech_recognition_optimized.py` –∫–∞–∫ –æ–ø–∏—Å–∞–Ω–æ
3. –ì–æ—Ç–æ–≤–æ! Diarization —Ä–∞–±–æ—Ç–∞–µ—Ç –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π

### –í–∞—Ä–∏–∞–Ω—Ç B: pyannote-2.1 (–ª—É—á—à–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å)

1. –ó–∞–ø—É—Å—Ç–∏—Ç–µ: `python test_diarization_alternatives.py`
2. –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –¥–æ—Å—Ç—É–ø–Ω–∞, –æ–±–Ω–æ–≤–∏—Ç–µ –∫–æ–¥ –∫–∞–∫ –æ–ø–∏—Å–∞–Ω–æ –≤—ã—à–µ
3. –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç–µ —Å–µ—Ä–≤–µ—Ä

---

## üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è

**–ù–∞—á–Ω–∏—Ç–µ —Å –í–∞—Ä–∏–∞–Ω—Ç–∞ A (–ø—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞)** - —Ä–∞–±–æ—Ç–∞–µ—Ç —Å—Ä–∞–∑—É –∏ –¥–∞–µ—Ç –ø—Ä–∏–µ–º–ª–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ —Å–ª—É—á–∞–µ–≤ (–¥–∏–∞–ª–æ–≥–∏, –∏–Ω—Ç–µ—Ä–≤—å—é).

–ï—Å–ª–∏ –Ω—É–∂–Ω–∞ –≤—ã—Å–æ–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å - –ø–µ—Ä–µ—Ö–æ–¥–∏—Ç–µ –∫ **–í–∞—Ä–∏–∞–Ω—Ç—É B (pyannote-2.1)**.


